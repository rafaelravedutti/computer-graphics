
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="./resources/css/print.css">

    <meta name="lecture" content="Computer Graphics">
    <meta name="exerciseNr" content="8">
    <meta name="exercisePrefix" content="Exercise">
    <meta name="term" content="Winter Term 2018/19">
    <meta name="dueDate" content="December 14, 2018, 11:59 am">

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>

    <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

    <script type="text/javascript" src="./resources/js/sheet.js"></script>

    <script type="text/javascript" src="./Basic/gl-matrix.js"></script>
</head>


<body>

    <page size="A4">
        <content>

            <exercise prefix="Basic Exercises" title="Textures" points=10>
                <task title="Bilinear Interpolation / MIP Mapping" points=6 submitfile="Basic1.js">
                    <subtask title="Bilinear Interpolation" points=2 submitfile="Basic1.js">
                        <p>
                            In the context of textures, bilinear interpolation is very important.
                            Your task is to implement bilinear interpolation instead of nearest neighbour interpolation for the setup shown below.
                            Colors are given at the black points;
                            the nearest neighbour interpolation in the left square shows you which colors the points have.
                        </p>
                        <p>
                            Follow the instructions in the source code and implement the bilinear sampling method <code>Basic1a.sampleBilinear</code>.
                            Make use of the given helper functions.
                            Once you are done, the square in the middle should look like the square on the right.
                        </p>
                        <p>
                            <center>
                                <img style="float:right; padding:0px; margin:0px;" width="200" height="200" src='./images/bilinearInterpolation.png' />
                                <canvas style="float:right; padding:0px; margin:0px;" id="canvasBasic1a" width=400 height=200 data-call="Basic1a.start" data-call-src="./Basic/Basic1.js"></canvas>
                            </center>
                        </p>
                    </subtask>

                    <subtask title="MIP Mapping" points=4 submitfile="Basic1.js">
                        <p>
                            This subtask is about <b>MIP Mapping</b>.
                            The first aim is to build the MIP map pyramid.
                            Follow the instructions in the constructor <code>MipMap(texture1D, nLevelMax)</code>.
                            After implementation you should see the coarser two levels of the MIP map pyramid, which are currently black, depicted in color (beneath the surface).
                        </p>
                        <p>
                            Next, you should use the MIP map pyramid to set the colors of the pixels in the image plane.
                            Currently we always use the finest level of the pyramid.
                            You have to adapt the code in <code>Basic1b.Render()</code> accordingly (see <code>TODO</code>s).
                            The idea is to compute the footprint of a pixel in the texture.
                            If the footprint is larger than the texel size of a level, you should use a coarser level.
                            The footprint of a pixel can be computed by the distance of the top and bottom texture coordinate of the pixel (These coordinates are already computed, see comments in the source code!).
                        </p>
                        <p>
                            You can adjust the number of pixels on the image plane shown below: <input type="range" id="nPixels" value="2" min="1" max="10" onchange="Basic1b.onChangeNPixels(this.value);" />
                        </p>
                        <canvas class="floatRight" id="canvasBasic1b" width=600 height=300 data-call="Basic1b.start" data-call-src="./Basic/Basic1.js">
                            <img class="wait">
                        </canvas>

                    </subtask>
                </task>

                <task title="Anti-Aliasing for Procedural Noise" points=4 submitfile="shader_noise_adapted.fs">
                    <img class="floatRight" id="noise_simple" width="160" src='./images/noise_only.png' />
                    <p>
                        In this task, we consider procedural texturing rather than textures from images.
                        The function <code>snoise</code> you find in the fragment shader <code>shader_noise_adapted.fs</code> returns a grey value for each 2D texture coordinate, resulting 
                        in a noisy but coherent image (see image on the right).
                        By multiplying the texture coordinates with $b \cdot 2^{f}$ before passing it to <code>snoise</code>, you get noise with different frequencies.
                        The images below are made using a base frequency of $b=12$ and $f=0, 1, 2, 3$.
                        The base frequency is stored in <code>baseFreq</code>.
                    </p>
                    <img class="floatRight" id="noise" width="640" src='./images/noise.png' />
                    <p>
                        The function <code>fbm</code> takes these and aggregates them to composite noise consisting of more than one frequency. 
                        The images below show aggregate noise (from left to right: only $f=0$, $f=0$ and $f=1$,...). 
                        One can use noise like this as a basis for effects like fire, smoke, water etc.
                    </p>
                    <img class="floatRight" id="aggregated_noise" width="640" src='./images/aggregated_noise.png' />
                    <p>
                        The two planes below are textured with the noise on the very right.
                    </p>
                    <p>
                        Now let's move the textured planes:
                        You can either move them manually by pressing the W and S key ore turn on alternating forward and backward motion using the checkerbox.
                        As you will notice, once the planes move farther away from the viewer, minification and therefore aliasing occurs on the procedurally generated noise pattern,
                        and flickering arises.
                    </p>
                    <img class="floatRight" id="aggregated_noise03" width="160" src='./images/aggregated_noise03.png' />
                    <p>
                        Your task is to perform a method similar to MIP mapping, but adapted to procedural noise like the one generated here:
                        The idea is to only use lower frequencies when the plane is far away to avoid ugly flickering artifacts during movement.
                        Therefore, you have to compute the derivative of the texture coordinate and deduce the right frequency maximum for the current distance.
                        Note that as a factor, also non-integer values are possible. 
                        Especially, you can also have factors below 1, leading to greyish images when the plane is far away (see image on the right, 0.3$\times$base).
                    </p>
                    <p>
                        Follow the <code>TODO</code>s in <code>shader_noise_adapted.fs</code> to perform this anti-aliasing approach.
                        The two planes below will always move in a synchronized manner, so that you can directly compare the two versions with (right, shader after your changes) and without
                        (left, shader before your changes) anti-aliasing.
                    </p>
                    
                    <canvas class="floatRight" id="canvasRight" width=300 height=300 data-call="Basic2.webGLStart" data-call-src="./Basic/Basic2.js">
                        <img class="wait">
                        <shader id="shader-vs-noise" type="--vertex" src="./Basic/shader_noise.vs"></shader>
                        <shader id="shader-fs-noise-adapted" type="--fragment" src="./Basic/shader_noise_adapted.fs"></shader>
                    </canvas>
                    <canvas id="canvasLeft" width=300 height=300 data-call="Basic2_before.webGLStart" data-call-src="./Basic/Basic2_before.js">
                        <img class="wait">
                        <shader id="shader-vs-noise" type="--vertex" src="./Basic/shader_noise.vs"></shader>
                        <shader id="shader-fs-noise" type="--fragment" src="./Basic/shader_noise.fs"></shader>
                    </canvas>

                    <fieldset class="floatRight">
                        <p>
                            <span style="display:inline-block; width:20px;"></span>
                            <input type="checkbox" id="motion" onchange="Basic2.onChangeMotion(); Basic2_before.onChangeMotion();"> motion
                        </p>
                    </fieldset>
                </task>
            </exercise>
        </content>
    </page>


    <page size="A4">
        <content>

            <exercise prefix="Advanced Exercises" title="Spherical Texture Mapping" points=10>

                <task title="Earth Texture Mapping - Part II" points=10 submitfile="earth.glsl, clouds.glsl">
                    <p>
                        From last week, you already know the earth and the universe. 
                        This week, it is time to add some realistic detail using normal mapping / bump mapping and a cloud overlay.
                    </p>
                    <subtask title="Normal Mapping in Per Vertex Tangent Space" points="3">
                        <p>
                            The normals stored in the normal texture are in tangent space.
                            To use them, they have to be converted to world space with the TBN matrix.
                            The TBN matrix is a 3x3 orthonormal matrix consisting of the tangent (T), bitangent (B), and normal (N) as column vectors.
                            The normal N is already known for every vertex.
                            In Exercise 5, you learned a way of constructing an orthonormal basis from a single unit vector.
                            This does <b>not</b> work here, because there are indefnite possible orthonormal bases and we have to choose the one that was used when creating the normal map.
                            Fortunately, every normal map aligns T and B to the texture coordinates.
                        </p>
                        <p>
                            The tangent and bitangent for spheres with spherical texture coordinates (as we are using here) are very simple to compute.
                            In object space, all T's are in the x-z plane (parallel to the equator) and all B's are perpendicular to T and N.
                            Compute T and B for every vertex in <code>earth.glsl</code> like that:
                            \[T = (0,1,0)^T \times N \]
                            \[B = N \times T \]
                            In the fragment shader, use the interpolated vectors to create the TBN matrix and use it to transform the normal read from the texture to world space.
                            Hint: Don't forget to normalize each vector.
                        </p>
                        <p>
                            Once you have implemented this part, you can see the result of normal mapping when you switch to 'Vertex TBN'. It should look like the following image:
                        </p>
                        <img class="floatRight" src="images/afterNormal.png" width=600>
                    </subtask>
                    <subtask title="Normal Mapping in Per Fragment Tangent Space" points="3">
                        <p>
                            As described above, the tangent, bitangent, and normal build an orthonomal basis aligned to the uv coordinates.
                            When having knowledge about the partial screen space derivatives both of the
                            world position ($p_x=(p_{x1},p_{x2},p_{x3}),p_y=(p_{y1},p_{y2},p_{y3})$) and of the respective texture coordinates ($c_x=(c_{x1},c_{x2}),c_y=(c_{y1},c_{y2})$),
                            the tangent and bitangent can also be computed directly:
                            \[ T = (p_y \times N) c_{x1} + (N \times p_x) c_{y1}\]
                            \[ B = (p_y \times N) c_{x2} + (N \times p_x) c_{y2}\]
                            The only problem right now is the computation of the screen space derivatives,
                            because for example a central difference in x direction would require each fragment to know
                            the values of the left and right neighbour.
                            Fortunately, OpenGL provides the built-in functions <code>dFdx</code> and <code>dFdy</code>
                            that do these derivatives for you.
                            For example, <code>dFdx</code> takes as input a varying variable from the vertex shader and returns the central difference in x direction.
                        </p>
                        <p>
                            Use <code>dFdx</code>, <code>dFdy</code>, and the formulas for normal mapping in the fragment shader.
                            If you have implemented this task correctly, it should look <b>exactly</b> like the per vertex normal mapping of task 8.3 a).
                        </p>
                    </subtask>
                    <subtask title="Bump Mapping" points="2">
                        <p>
                            In addition to a normal map, we also added a height map of the earth in <code>earthBump</code>.
                            You can use this height map to translate every vertex along its normal according to the height sample.
                        </p>
                        <p>
                            Implement bump mapping in the vertex shader (= tesselation evaluation shader) of <code>earth.glsl</code>.
                            Use the uniform <code>heightScale</code> to control the shifted distance.
                            Translate the vertices in <b>objectSpace</b>.
                        </p>
                        <p>
                            Play around with the 'tesselation factor' in the GUI to change the number of vertices and therefore the detail level of the earth surface.
                            Different to normal mapping, bump mapping also alters the shape of the earth's silhouette:
                        </p>
                        <img class="floatRight" src="images/afterBump.png" width=600>
                    </subtask>

                    <subtask title="Clouds" points="2">
                        <p>
                            In this task you are asked to add clouds to our earth.
                            The clouds are rendered in white with alpha blending enabled.
                            Read the cloud map in <code>clouds.glsl</code> and set the alpha value appropriately to display smooth clouds.
                            Make sure no clouds are visible on the night side of the earth
                            and smoothly blend them in as you did with the day texture.
                        </p>
                        <p>
                            Next, we want to add fake cloud shadows on the earth.
                            Sample the cloud map in <code>earth.glsl</code> and diminish the incoming light
                            on the earth surface according to the cloud map value.
                            On the night side of the earth this shadowing should not have an effect.
                            When you are done, the final image should look like this:
                        </p>
                        <img class="floatRight" src="images/afterClouds.png" width=600>
                    </subtask>
                </task>


            </exercise>
        </content>
    </page>
</body>

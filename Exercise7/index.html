
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="./resources/css/print.css">

    <meta name="lecture" content="Computer Graphics">
    <meta name="exerciseNr" content="7">
    <meta name="exercisePrefix" content="Exercise">
    <meta name="term" content="Winter Term 2018/19">
    <meta name="dueDate" content="December 5, 2018, 11:59 am">

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>

    <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

    <script type="text/javascript" src="./resources/js/sheet.js"></script>

    <script type="text/javascript" src="./Basic/gl-matrix.js"></script>

    <style>
        #div0, #div1, #div2, #div3 {
            float: left;
            width: 150px;
            height: 100px;
            margin: 5px;
        }
    </style>
</head>


<body>

    <page size="A4">
        <content>

            <exercise prefix="Basic Exercises" title="Transparency & Textures" points=10>
                
                <task title="Alpha Blending" points=3 submitfile="Basic1.js">

                    <p>
                        In this task, you should implement correct alpha blending of the four colored circles you see below. The composed image should have a
                        background of pure white, and the circles should be blended onto it from left to right (initial order: blue - red - yellow - green).
                        You can alter the order of the circles and therefore of the blending process using drag-and-drop. The alpha values
                        (ranging from $0$ to $1$, preset to $0.5$) can be modified using the sliders below the circle images.
                    </p>
                    <p>
                        Follow the instructions in the <code>TODO</code>s to implement the function <code>doAlphaBlending()</code> and fill the canvas below
                        the images with a blended version of the four circles.  Note that, for every image, only the circle
                        and not its background should be blended, which is why it is transparent.
                        Transparency of background pixels is annotated with a zero alpha channel value which you will have to use in your implementation.
                    </p>

                    <div id="div0" ondrop="Basic1.drop(event)" ondragover="Basic1.allowDrop(event)">
                        <img src="./images/blue.png" width=150 height=100 draggable="true" ondragstart="Basic1.drag(event)" id="drag0">
                    </div>

                    <div id="div1" ondrop="Basic1.drop(event)" ondragover="Basic1.allowDrop(event)">
                        <img src="./images/red.png" width=150 height=100 draggable="true" ondragstart="Basic1.drag(event)" id="drag1">
                    </div>

                    <div id="div2" ondrop="Basic1.drop(event)" ondragover="Basic1.allowDrop(event)">
                        <img src="./images/yellow.png" width=150 height=100 draggable="true" ondragstart="Basic1.drag(event)" id="drag2">
                    </div>

                    <div id="div3" ondrop="Basic1.drop(event)" ondragover="Basic1.allowDrop(event)">
                        <img src="./images/green.png" width=150 height=100 draggable="true" ondragstart="Basic1.drag(event)" id="drag3">
                    </div>
                    <table>
                        <tr>
                            <td> $\alpha$: <input type="range" id="alpha0" name="alpha" value="0.5" min="0" max="1" step="0.1" onchange="Basic1.onChangeAlpha(0, this.value);" style="width: 100px;" /></td>
                            <td> $\alpha$: <input type="range" id="alpha1" name="alpha" value="0.5" min="0" max="1" step="0.1" onchange="Basic1.onChangeAlpha(1, this.value);" style="width: 100px;" /> </td>
                            <td> $\alpha$: <input type="range" id="alpha2" name="alpha" value="0.5" min="0" max="1" step="0.1" onchange="Basic1.onChangeAlpha(2, this.value);" style="width: 100px;" /> </td>
                            <td> $\alpha$: <input type="range" id="alpha3" name="alpha" value="0.5" min="0" max="1" step="0.1" onchange="Basic1.onChangeAlpha(3, this.value);" style="width: 100px;" /> </td>
                        </tr>
                    </table>
                    <p>
                        <center>
                            <canvas id="canvasBasic1" width=300 height=200 data-call="Basic1.start" data-call-src="./Basic/Basic1.js">
                                <img class="wait">
                            </canvas>
                        </center>
                    </p>
                    <p>
                        Once you are done, you can play around with the alpha values and the blending order to observe different effects. Note that you can
                        also completely hide a circle by setting its alpha value to $0$.
                    </p>

                </task>

                <task title="Perspective Contortion" points=3 submitfile="Basic2.js, Basic2.txt">
                    <p>
                        This assignment will give you a look at perspective contortion and its consequences for rasterization.
                        A triangle $\Delta ABC$ with $A = (0, 0, -1)^T$, $B = (0, 2, -3)^T$ and $C = (-2, -1, -3)^T$ is given.
                        This triangle contains another triangle which consists of the centers of the edges $AB$, $BC$ and $CA$.
                        Furthermore, a projection matrix $M$ is given which transforms $\Delta ABC$ such that $A'$ lies at the near plane and $B'$ and $C'$ lie on the far plane.
                        $$
                        M=\left[
                        \begin{array}{rrrr}
                        1 & 0 & 0 & 0 \\
                        0 & 1 & 0 & 0 \\
                        0 & 0 & -2 & -3 \\
                        0 & 0 & -1 & 0
                        \end{array}
                        \right]
                        $$
                        <ol>
                            <li>
                                Compute the transformed and dehomogenized vertices $A'$, $B'$ and $C'$.
                                Make use of the given helper functions (see comments in the source file).
                            </li>
                            <li>
                                Compute the centers of the edges $P_{A',B'}$, $P_{B',C'}$ and $P_{C',A'}$ from $A'$, $B'$ and $C'$.
                                Is the drawn inner triangle perspectively correct?
                                Which interpolation method do you know that would provide the same result?
                            </li>
                            <li>
                                Compute the transformed and dehomogenized centers of the edges $P_{A,B}'$, $P_{B,C}'$ and $P_{C,A}'$ from $P_{A,B}$, $P_{B,C}$ and $P_{C,A}$.
                                Is the drawn inner triangle perspectively correct?
                            </li>
                        </ol>
                    </p>
                    <p>
                        Give answers to the theoretical questions in <code>Basic2.txt</code>!
                    </p>
                    <p>
                        <canvas id="canvasBasic2_1" width=200 height=200 data-call="Basic2_1.start" data-call-src="./Basic/Basic2.js">
                            <img class="wait">
                        </canvas>
                        <canvas id="canvasBasic2_2" width=200 height=200 data-call="Basic2_2.start" data-call-src="./Basic/Basic2.js">
                            <img class="wait">
                        </canvas>
                        <canvas id="canvasBasic2_3" width=200 height=200 data-call="Basic2_3.start" data-call-src="./Basic/Basic2.js">
                            <img class="wait">
                        </canvas>

                    </p>
                </task>

                <task title="Textures in WebGL" points=4  submitfile="Basic3.js, shader_texture.vs, shader_texture.fs">
                    <p>
                        In this task, you should texture a plane, first with a texture containing colors, second with a texture
                        containing normals. Right now, you look at the plane (which is colored grey) from the top. You can change
                        the viewing angle using the <code>W</code> and <code>S</code> keys. There is a point light source hovering
                        over the plane, like in the Phong shading task of Basic Exercises 6.
                    </p>
                    <subtask title="Texture Mapping" points="2">
                        <img class="floatRight" id="checkerboard_show" width="150" height="150" src='./resources/checkerboard.png' />
                        <p>
                            On the right, you see a checkerboard texture. Several steps are needed to apply this texture
                            to the plane.
                        </p>
                        <p>
                            <ol>
                                <li>
                                    Set up the texture from the provided image.
                                </li>
                                <li>
                                    In the vertex shader you can find an attribute for the texture coordinates. Define a varying
                                    variable to pass them to the fragment shader. Assign the attribute to the varying variable.
                                    Note that the WebGL warning "WebGL warning: vertexAttribPointer: -1 is not a valid index."
                                    will disappear once you have done this. The warning appears because when <code>vTexCoord</code> is
                                    unused, the shader compiler omits it and its location cannot be found.
                                </li>
                                <li>
                                    In the fragment shader, define the same varying variable to receive the texture coordinates
                                    from the vertex shader. Define a uniform sampler holding the texture to be passed, and sample
                                    the texture at the texture coordinates.
                                </li>

                            </ol>
                        </p>
                        <p>
                            Once the texture is set up correctly, you see the texture in the upper left corner of the plane,
                            where the texture coordinates are smaller than $1$. To repeat the texture for texture coordinates greater than $1$ rather than clamping
                            it to the nearest value, you can check the associated checkbox. Have a look at <code>onChangeRepeat()</code>
                            to see how it works.
                        </p>
                        <p>
                            As soon as repeating is enabled, the texture covers the entire plane. When you change
                            the view angle, however, minification occurs in areas farther away, and ugly patterns arise.
                            To change this, enable MIP mapping by checking the associated checkbox. Have a look at <code>onChangeMipmap()</code>
                            to see how it works. 
                            In next week's lecture, you will see what MIP mapping is and how it is used to prevent minification artifacts!
                        </p>
                    </subtask>
                    <subtask title="Normal Mapping" points="2">
                        <img class="floatRight" id="cobblestone_show" width="150" height="150" src='./resources/cobblestone.png' />
                        <p>
                            A texture can also be used to store additional information of a surface, such as normals. On the right,
                            you see a so-called normal map which stores normals encoded as RGB triplets. Once these normals are used
                            for lighting computation in the fragment shader, the plane does not look flat anymore, but as if covered with
                            cobblestone. Find the appropriate <code>TODO</code>s in the two submission files and apply the normal
                            map to the plane! You can reuse the texture coordinates already used in the first subtask.
                            Be aware of two things: First, the normals are stored as colors, which means that their values have
                            been mapped to $[0,1]$. You have to bring them back to $[-1,1]$ to use the normals. Second, unlike in the last
                            subtask, the plane should be covered with one single, unrepeated instance of the texture. Therefore, you have
                            to change the texture coordinates to be in range $[0,1]$ rather than $[0,width]$ and $[0,height]$, respectively
                            ($width$ and $height$ are given in the uniform <code>planeSize</code>!).
                        </p>
                    </subtask>
                    <fieldset class="floatRight">
                        <p>
                            <input type="radio" name="texture" value="checkerboard" onchange="Basic3.onChangeTexture(0);" checked> checkerboard texture
                            <span style="display:inline-block; width:100px;"></span>
                            <input type="radio" name="texture" value="cobblestone" onchange="Basic3.onChangeTexture(1);"> cobblestone normal texture
                        </p>
                        <p>
                            <span style="display:inline-block; width:30px;"></span>
                            <input type="checkbox" id="repeat" onchange="Basic3.onChangeRepeat();"> repeat the texture
                        </p>
                        <p>
                            <span style="display:inline-block; width:30px;"></span>
                            <input type="checkbox" id="mipmap" onchange="Basic3.onChangeMipmap();"> enable MIP mapping
                        </p>
                    </fieldset>
                    <img id="checkerboard" src='./resources/checkerboard.png' style="display:none" />
                    <img id="cobblestone" src='./resources/cobblestone.png' style="display:none" />
                    <canvas class="floatRight" id="canvasTexturing" width=600 height=600 data-call="Basic3.webGLStart" data-call-src="./Basic/Basic3.js">
                        <img class="wait">
                        <shader id="shader-vs-phong" type="--vertex" src="./Basic/shader_texture.vs"></shader>
                        <shader id="shader-fs-phong" type="--fragment" src="./Basic/shader_texture.fs"></shader>
                        <shader id="shader-vs-light" type="--vertex" src="./Basic/shader_light.vs"></shader>
                        <shader id="shader-fs-light" type="--fragment" src="./Basic/shader_light.fs"></shader>
                    </canvas>

                </task>
            </exercise>
        </content>
    </page>


    <page size="A4">
        <content>

            <exercise prefix="Advanced Exercises" title="Spherical Texture Mapping" points=10>


                <task title="Spherical Coordinates" points=5 submitfile="helper.glsl, universe.glsl">
                    <p>
                        Spherical coordinates are used to describe positions on a sphere. 
                        They consist of two angles $\Theta$ (=theta) and $\Phi$ (=phi) and the distance $r$ of the point to the sphere center. 
                        In this exercise we are only interested in surface points of the unit sphere. Therefore, the radius is neglected. 
                        Check out the <a href="http://mathworld.wolfram.com/SphericalCoordinates.html">Wolfram</a> article for more informations, 
                        but keep in mind that we use a slightly different coordinate system with x pointing to the right and y upwards.
                    </p>

                    <subtask title="Coordinate Conversions" points="3">
                        <p>
                            Given a point $X = (x,y,z)$ with $|X| = 1$, the spherical coordinates of $X$ are:
                            \[ \Theta = \text{tan}^{-1} \left( \frac{z}{x} \right) \]
                            \[ \Phi = \text{cos}^{-1} \ y  \]
                            Compute the spherical coordinates of a point in the function <code>cartesianToSpherical</code> in <code>helper.glsl</code>. Return the angles in a vector of the form <code>vec2(theta,phi)</code>.
                        </p>
                        <p>
                            The transformation from spherical coordinates back to cartesian coordinates is defined as:
                            \[ x = \text{sin} \ \Phi \ \text{cos} \ \Theta \]
                            \[ y = \text{cos} \ \Phi  \]
                            \[ z = \text{sin} \ \Phi \ \text{sin} \ \Theta \]
                            Computer this conversion in <code>sphericalToCartesian</code>.
                        </p>

                        <p>
                            As you have seen in the basic exercise, the texture coordinates u and v are in the range [0,1]. 
                            Unfortunately, $\Theta$ is in the range $[-\pi,\pi]$ and $\Phi$ in the range $[0,\pi]$. 
                            Implement the function <code>sphericalToTexture</code> that maps the spherical coordinates to texture coordinates. 
                            Note that the texture coordinates must be <b>mirrored</b> to give correct results.
                        </p>

                    </subtask>


                    <subtask title="The Universe" points="2">
                        <p>
                            In this task we want to show a universe texture in the background. 
                            For this purpose a screen space quad is already rendered behind every other object. 
                            Compute the world position of each fragment of the quad in <code>universe.glsl</code>. 
                            After that, compute the viewing direction in world space and use the method implemented in the previous exercise to sample the universe texture. 
                            If everything is correct your scene should look like this:
                        </p>
                        <img class="floatRight" src="images/universe.png" width=600>
                    </subtask>
                </task>


                <task title="Earth Texture Mapping - Part I (to be continued)" points=5 submitfile="earth.glsl">
                    <p>
                        <b>Important:</b> </br>
                        To better visualize the effect of bump mapping on the mesh, we added tesselation to dynamically subdivide each triangle in multiple smaller triangles. 
                        You do not have to care about the tesselation process because everything is already implemented, but you have to know that each vertex of the fine mesh is passed through the "Tesselation Evaluation" shader. 
                        This "Tesselation Evaluation" shader behaves identically to a vertex shader and variables can be passed to the fragment shader like you have done it before. 
                        That is why when we talk about the vertex shader in the following tasks, we actually mean the tesselation evaluation shader. 
                        If you are interested and want to know more about tesselation, feel free to read the code, ask the tutors, search the web, and of course join our "Interactive Computer Graphics" lecture in the next semester :).
                    </p>

                    <subtask title="Day and Night Shading" points="2">
                        <p>
                            The basic Phong shading you know from previous exercises is already implemented. 
                            In this task we want to show the 'night texture' of the earth (lights around big cities etc.) when the surface is facing away from the light. 
                            Read from the day and night texture and blend between these values in <code>earth.glsl</code>. 
                            Make sure the transition is smooth. 
                            The texture coordinates are passed in the variable <code>tc</code> and should already be correct if you implemented the previous task.
                        </p>
                    </subtask>
                    <subtask title="Specular Light" points="3">
                        <p>
                            The specular coefficient (not the exponent!) for each earth surface point is stored in the 'earthSpec' texture. 
                            Read this value and use it in the lighting computation. 
                            You can better observe the effect of the varying specular intensity when disabling color.
                            After this subtask the scene should look like this:
                        </p>
                        <img class="floatRight" src="images/afterColor.png" width=600>
                    </subtask>
                   
                </task>


            </exercise>
        </content>
    </page>
</body>
